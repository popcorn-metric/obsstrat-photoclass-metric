{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BEWARE!\n",
    "need to run this notebook one folder down from lsst package install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.cosmology import Planck15 as cosmo\n",
    "from astropy.table import Table\n",
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.integrate as integrate\n",
    "import scipy.interpolate as interpolate\n",
    "import sncosmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lsst.sims.maf.db as db\n",
    "import lsst.sims.maf.utils as utils\n",
    "import lsst.sims.maf.metrics as metrics\n",
    "import lsst.sims.maf.slicers as slicers\n",
    "import lsst.sims.maf.plots as plots\n",
    "import lsst.sims.maf.metricBundles as metricBundles\n",
    "from lsst.sims.utils import equatorialFromGalactic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_cosmology = cosmo\n",
    "\n",
    "def random_ra_dec(size=None):\n",
    "    if size == None:\n",
    "        use_size = 1\n",
    "    else:\n",
    "        use_size = size\n",
    "    \n",
    "    p, q = np.random.random((2, use_size))\n",
    "\n",
    "    ra = 360. * p\n",
    "    dec = np.arcsin(2. * (q - 0.5)) * 180 / np.pi\n",
    "\n",
    "    if size == None:\n",
    "        return ra[0], dec[0]\n",
    "    else:\n",
    "        return ra, dec\n",
    "\n",
    "class SourceDistribution():\n",
    "    def count(self, time):\n",
    "        pass\n",
    "\n",
    "    def simulate(self, count, start_time, end_time, flat_redshift=False):\n",
    "        pass\n",
    "\n",
    "class VolumetricSourceDistribution(SourceDistribution):\n",
    "    \"\"\"Model sources that are equally distributed across the sky.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    volumetric_rate : float or function\n",
    "        The volumetric rate in counts/yr/Mpc**3. This can be either a float\n",
    "        representing a constant rate as a function of redshift\n",
    "        or a function that takes the redshift as a parameter and returns the\n",
    "        volumetric rate at that redshift.\n",
    "    \"\"\"\n",
    "    def __init__(self, volumetric_rate, min_redshift=0., max_redshift=3.,\n",
    "                 cosmology=default_cosmology):\n",
    "        self.volumetric_rate = volumetric_rate\n",
    "        self.cosmology = cosmology\n",
    "\n",
    "        self._update_redshift_distribution(min_redshift, max_redshift)\n",
    "\n",
    "    def _update_redshift_distribution(self, min_redshift, max_redshift, redshift_bins=10000):\n",
    "        \"\"\"Set up the distribution to operate over a given redshift range.\n",
    "\n",
    "        This also creates and inverse CDF sampler to draw redshifts from.\n",
    "        \"\"\"\n",
    "        self.min_redshift = min_redshift\n",
    "        self.max_redshift = max_redshift\n",
    "\n",
    "        sample_redshift_range = np.linspace(\n",
    "            min_redshift, max_redshift, redshift_bins\n",
    "        )\n",
    "        normalized_rates = self.rate(sample_redshift_range)\n",
    "        normalized_rates /= np.sum(normalized_rates)\n",
    "        cum_rates = np.cumsum(normalized_rates)\n",
    "\n",
    "        self.redshift_cdf = interpolate.interp1d(\n",
    "            cum_rates,\n",
    "            sample_redshift_range\n",
    "        )\n",
    "\n",
    "    def rate(self, redshift):\n",
    "        \"\"\"Calculate the total rate of this source at a given redshift.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        redshift : float\n",
    "            The redshift to estimate the rate at.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        rate : float\n",
    "            The rate of this source at the given redshift in counts/yr/unit redshift\"\"\"\n",
    "        if callable(self.volumetric_rate):\n",
    "            rate = self.volumetric_rate(redshift)\n",
    "        else:\n",
    "            rate = self.volumetric_rate\n",
    "\n",
    "        rate = rate * self.cosmology.differential_comoving_volume(redshift).value * 4 * np.pi\n",
    "\n",
    "        return rate\n",
    "\n",
    "    def count(self, time):\n",
    "        \"\"\"Count how many transients we would expect to see in a given time.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        time : float\n",
    "            The time in years.\n",
    "        \"\"\"\n",
    "        return integrate.quad(self.rate, self.min_redshift, self.max_redshift)[0] * time\n",
    "\n",
    "    def simulate(self, count, start_time, end_time, flat_redshift=False):\n",
    "        \"\"\"Simulate transients\"\"\"\n",
    "        ref_count = self.count((end_time - start_time) * 365.2425)\n",
    "\n",
    "        if flat_redshift:\n",
    "            # Sample from a flat redshift distribution\n",
    "            redshifts = np.random.uniform(self.min_redshift, self.max_redshift, count)\n",
    "            weights = self.rate(redshifts) / count\n",
    "        else:\n",
    "            # Sample from the True redshift distribution\n",
    "            redshifts = self.redshift_cdf(np.random.random(size=count))\n",
    "            weights = np.ones(len(redshifts))\n",
    "            \n",
    "        ras, decs = random_ra_dec(count)\n",
    "\n",
    "        result = Table(\n",
    "            [redshifts, ras, decs, weights],\n",
    "            names=['z', 'ra', 'dec', 'weight'],\n",
    "        )\n",
    "\n",
    "        return result\n",
    "    \n",
    "class SALT2Distribution(VolumetricSourceDistribution):\n",
    "    def simulate(self, count, start_time, end_time, *args, **kwargs):\n",
    "        result = super().simulate(count, start_time, end_time, *args, **kwargs)\n",
    "\n",
    "        result['source'] = 'salt2-extended'\n",
    "        result['params'] = [('z', 't0', 'x1', 'c')]\n",
    "        \n",
    "        result['t0'] = np.random.uniform(start_time, end_time, count)\n",
    "        result['x1'] = np.random.normal(0, 1, count)\n",
    "        result['c'] = np.random.exponential(0.1, count)\n",
    "\n",
    "        result['peakabsmag'] = -19.1 - 0.13 * result['x1'] + 3.1 * result['c']\n",
    "        result['peakmagband'] = 'bessellb'\n",
    "        result['peakmagsys'] = 'ab'\n",
    "\n",
    "        return result\n",
    "    \n",
    "def generate_model(meta):\n",
    "    model = sncosmo.Model(source=meta['source'])\n",
    "\n",
    "    for param in meta['params']:\n",
    "        model[param] = meta[param]\n",
    "\n",
    "    model.set_source_peakabsmag(meta['peakabsmag'], meta['peakmagband'], meta['peakmagsys'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate survey\n",
    "# init\n",
    "base_mjd = 59580.\n",
    "survey_length = 10. * 365.\n",
    "\n",
    "# volumetric rate of Ias\n",
    "volumetric_rate = lambda z: 2.6e-5*(1+z)**1.5\n",
    "# simulate Ias light-curves parameters in these footprint\n",
    "d = SALT2Distribution(volumetric_rate, 0.0, 0.8)\n",
    "\n",
    "sim = d.simulate(10000, base_mjd, base_mjd + survey_length, flat_redshift=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sim outputs SNe Ia light-curve parameters\n",
    "# sim.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the slicer to evaluate the catalog we just made\n",
    "slicer = slicers.UserPointsSlicer(sim['ra'], sim['dec'], latLonDeg=True, badval=0)\n",
    "\n",
    "for key in sim.keys():\n",
    "    if key not in ['ra', 'dec']:\n",
    "        slicer.slicePoints[key] = sim[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observing strategy\n",
    "Generate light-curves for this observing cadence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Load observing strategy used for this experiment\n",
    "#This next command assumes you have downloaded a database into this directory\n",
    "OS_folder = os.environ['LSST_OS']\n",
    "opsdb = db.OpsimDatabase(f'{OS_folder}/cadence/kraken_2026.db')\n",
    "# Init of this experiment\n",
    "runName = 'test_sncosmo'\n",
    "outDir = 'test_sim_sncosmo'\n",
    "resultsDb = db.ResultsDb(outDir=outDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SNCosmoDetectabilityMetric(metrics.BaseMetric):\n",
    "    \"\"\"\n",
    "    Quantifies detectability of sncosmo objects.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ptsNeeded : int\n",
    "        Number of an object's lightcurve points required to be above the 5-sigma limiting depth \n",
    "        before it is considered detected.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    TODO: Update this\n",
    "    \n",
    "    This metric assumes this will be run with a slicer that has had extra \n",
    "    parameters (t0, peak, and slope) added to the slicer.slicePoint \n",
    "    dict (which already contains ra, dec, fieldID, etc). All the observation information \n",
    "    (MJD of observation, 5-sigma limiting depth of each observation, etc) is contained in the\n",
    "    dataSlice array. We request the filter information for each observation anticipating that\n",
    "    more general lightcurve functions will need it as input.\n",
    "    \"\"\"\n",
    "    def __init__(self, metricName='TestSNMetric', mjdCol='observationStartMJD', m5Col='fiveSigmaDepth',\n",
    "                 filterCol='filter', ptsNeeded=2, **kwargs):\n",
    "        self.mjdCol = mjdCol\n",
    "        self.m5Col = m5Col\n",
    "        self.filterCol = filterCol\n",
    "        self.ptsNeeded = ptsNeeded\n",
    "\n",
    "        super().__init__(col=[self.mjdCol, self.m5Col, self.filterCol],\n",
    "                         units='fraction',\n",
    "                         metricName=metricName,\n",
    "                         **kwargs)\n",
    "\n",
    "    def run(self, dataSlice, slicePoint=None):\n",
    "        # Generate the lightcurve for this object\n",
    "        model = generate_model(slicePoint)\n",
    "        bands = np.array([f'lsst{i}' for i in dataSlice[self.filterCol]])\n",
    "        fluxes = model.bandflux(bands, dataSlice[self.mjdCol], zp=25., zpsys='ab')\n",
    "        fluxerrs = 10**(-0.4*(dataSlice[self.m5Col] - 25)) / 5.\n",
    "\n",
    "        metric_val = {}\n",
    "        \n",
    "        npts = np.sum(fluxes > fluxerrs * 5.)\n",
    "        if npts >= self.ptsNeeded:\n",
    "            metric_val['detected'] = 1.\n",
    "        else:\n",
    "            metric_val['detected'] = 0.\n",
    "        \n",
    "        metric_val['model'] = model\n",
    "        metric_val['mjds'] = dataSlice[self.mjdCol]\n",
    "        metric_val['bands'] = bands\n",
    "        metric_val['fluxes'] = fluxes\n",
    "        metric_val['fluxerrs'] = fluxerrs\n",
    "\n",
    "        return metric_val\n",
    "\n",
    "    def reduceDetected(self, metric_val):\n",
    "        return metric_val['detected']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = SNCosmoDetectabilityMetric()\n",
    "#sql = 'night < %i and (filter=\"r\" or filter=\"i\" or filter=\"z\")' % (365.25*5)\n",
    "sql = ''\n",
    "\n",
    "summary_stats = [metrics.MeanMetric(maskVal=0)]\n",
    "\n",
    "plotFuncs = [plots.HealpixSkyMap()]\n",
    "bundle = metricBundles.MetricBundle(metric, slicer, sql, runName=runName, summaryMetrics=summary_stats, plotFuncs=plotFuncs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying database SummaryAllProps with no constraint for columns ['observationStartMJD', 'filter', 'fieldRA', 'fiveSigmaDepth', 'fieldDec'].\n",
      "Found 2438388 visits\n",
      "Running:  ['test_sncosmo_TestSNMetric_USER']\n",
      "Completed metric generation.\n",
      "Running reduce methods.\n",
      "Running summary statistics.\n",
      "Completed.\n",
      "CPU times: user 45.2 s, sys: 7.09 s, total: 52.3 s\n",
      "Wall time: 52.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "bundleList = [bundle]\n",
    "bundleDict = metricBundles.makeBundlesDictFromList(bundleList)\n",
    "bgroup = metricBundles.MetricBundleGroup(bundleDict, opsdb, outDir=outDir, resultsDb=resultsDb)\n",
    "bgroup.runAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bgroup.plotAll(closefigs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Total number of supernovae detected for each redshift\n",
    "# from scipy.stats import binned_statistic\n",
    "\n",
    "mask = ~bundle.metricValues.mask\n",
    "detected = np.array([i['detected'] for i in bundle.metricValues[mask]], dtype=bool)\n",
    "# mask_sim = sim[mask][detected]\n",
    "\n",
    "# bin_stat, bin_edges, binnumber = binned_statistic(mask_sim['z'], mask_sim['weight'], statistic='sum')\n",
    "# bin_widths = bin_edges[1:] - bin_edges[:-1]\n",
    "# bin_centers = (bin_edges[1:] + bin_edges[:-1]) / 2.\n",
    "# plt.figure()\n",
    "# plt.hlines(bin_stat, bin_edges[:-1], bin_edges[1:])\n",
    "\n",
    "# plt.xlabel('Redshift')\n",
    "# plt.ylabel('Number of SNe Ia detected')\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Plot a light curve\n",
    "# idx = 2\n",
    "\n",
    "# metric_val = bundle.metricValues[idx]\n",
    "# if not metric_val:\n",
    "#     raise Exception(f\"Index {idx} is masked!\")\n",
    "\n",
    "# model = metric_val['model']\n",
    "# mjds = metric_val['mjds']\n",
    "# fluxes = metric_val['fluxes']\n",
    "# fluxerrs = metric_val['fluxerrs']\n",
    "# bands = np.array(metric_val['bands'])\n",
    "\n",
    "# band_plot_colors = {\n",
    "#     \"lsstu\": \"C6\",\n",
    "#     \"lsstg\": \"C4\",\n",
    "#     \"lsstr\": \"C0\",\n",
    "#     \"lssti\": \"C2\",\n",
    "#     \"lsstz\": \"C3\",\n",
    "#     \"lssty\": \"goldenrod\",\n",
    "# }\n",
    "\n",
    "# plt.figure()\n",
    "\n",
    "# min_mjd = np.min(mjds[fluxes > 0.001]) - 30\n",
    "# max_mjd = np.max(mjds[fluxes > 0.001]) + 30\n",
    "# plot_mjds = np.arange(min_mjd, max_mjd)\n",
    "\n",
    "# for band in band_plot_colors:\n",
    "#     match = bands == band\n",
    "#     c = band_plot_colors[band]\n",
    "\n",
    "#     plt.errorbar(mjds[match], fluxes[match], fluxerrs[match], fmt='o', c=c, label=band)\n",
    "\n",
    "#     model_flux = model.bandflux(band, plot_mjds, 25.0, 'ab')\n",
    "#     plt.plot(plot_mjds, model_flux, c=c)\n",
    "\n",
    "# plt.xlim(min_mjd, max_mjd)\n",
    "# plt.legend()\n",
    "# plt.xlabel('MJD (days)')\n",
    "# plt.ylabel('Flux (zp=25.0 AB)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reformat light-curves into Pandas DataFrame\n",
    "If necessary, save them in SNANA format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init\n",
    "# outDir = './test_sim_sncosmo/'\n",
    "# os.makedirs(outDir,exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_to_pandas(bundle,detected):\n",
    "    # create pandas dataframe with info for PHOT.csv\n",
    "    tmp ={}\n",
    "    dict_data = {}\n",
    "    dict_keys = {'SNID':'SNID','mjds':'MJD', 'bands':'FLT', 'fluxes':'FLUXCAL', 'fluxerrs':'FLUXCALERR'}\n",
    "    for key in ['SNID','MJD', 'FLT', 'FLUXCAL', 'FLUXCALERR']:\n",
    "        tmp[key] = []\n",
    "    end = len(bundle.metricValues[~bundle.metricValues.mask][detected])\n",
    "    for key in ['mjds', 'bands', 'fluxes', 'fluxerrs']:\n",
    "        for i in range(end):\n",
    "            if key == 'mjds':\n",
    "                # fill SNID\n",
    "                tmp['SNID'].append(np.ones(len(bundle.metricValues[~bundle.metricValues.mask][detected][i][key]))*i)\n",
    "            tmp[dict_keys[key]].append(bundle.metricValues[~bundle.metricValues.mask][detected][i][key].tolist())\n",
    "        dict_data[dict_keys[key]] = np.concatenate(tmp[dict_keys[key]])\n",
    "    dict_data['SNID'] = np.concatenate(tmp['SNID'])\n",
    "    #Data Frame\n",
    "    df = pd.DataFrame.from_dict(dict_data)\n",
    "    # Reformatting into SNANA friendly format\n",
    "    phot = df[df['FLUXCAL']!=0.0]\n",
    "    phot['SNID'] = phot['SNID'].astype(int)\n",
    "    phot['FLT'] = phot['FLT'].astype(str)\n",
    "    # change filter naming (SNANA default is Y for LSST)\n",
    "    phot['FLT'] = phot['FLT'].apply(lambda x: 'Y' if x=='y' else x)\n",
    "    phot['FLT'] = phot['FLT'].astype(str).str.strip('lsst')\n",
    "    return phot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sim_to_pandas(bundle,detected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if saving to SNANA-like csv\n",
    "# with header & photometry\n",
    "# un-comment below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def save_HEAD(sim,mask,detected,outDir):\n",
    "#     # create pandas dataframe with info for HEAD.csv\n",
    "#     # sim[mask].keys()\n",
    "#     df = pd.DataFrame()\n",
    "#     df[['SIM_REDSHIFT_CMB','RA','DECL','PEAKMJD','SIM_SALT2x1','SIM_SALT2c','SIM_PEAKMAG_b']] = sim[mask][detected][['z','ra','dec','t0','x1','c','peakabsmag']].to_pandas()\n",
    "#     # tag the type SNIa\n",
    "#     df['SNTYPE']=np.ones(len(df)).astype(int)*101\n",
    "#     # create IDs\n",
    "#     df['SNID']= df.index\n",
    "#     df.to_csv(f\"{outDir}/DAT_HEAD.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_HEAD(sim,mask,detected,outDir)\n",
    "# df.to_csv(f\"{outDir}/DAT_PHOT.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SuperNNova classification for these objects\n",
    "requirements:  supernnova (pip install supernnova) and its dependencies e.g. torch (see https://pytorch.org), tqdm, colorama, seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def photo_class_accuracy(device, model_file):\n",
    "    from supernnova.validation.validate_onthefly import classify_lcs\n",
    "    # SNN init\n",
    "    pred_probs = classify_lcs(df, model_file, device)\n",
    "    # get accuracy\n",
    "    preds = np.bincount(np.argmax(pred_probs,axis=-1).reshape(-1))\n",
    "    acc = preds[0]/(preds[0]+preds[1])\n",
    "    \n",
    "    return round(acc*100,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu' # change to GPU if it is available\n",
    "model_file = f'{OS_folder}/obsstrat-photoclass-metric/pretrained_models/LSST_cad_vanilla_S_0_CLF_2_R_none_photometry_DF_1.0_N_global_lstm_32x2_0.05_128_True_mean_C/vanilla_S_0_CLF_2_R_none_photometry_DF_1.0_N_global_lstm_32x2_0.05_128_True_mean_C.pt' # pre-trained SuperNNova model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 14.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VanillaRNN(\n",
      "  (rnn_layer): LSTM(76, 32, num_layers=2, dropout=0.05, bidirectional=True)\n",
      "  (output_dropout_layer): Dropout(p=0.05, inplace=False)\n",
      "  (output_layer): Linear(in_features=64, out_features=2, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "68.73"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "photo_class_accuracy(device, model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
